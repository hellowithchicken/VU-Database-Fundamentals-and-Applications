{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE-3ff-nC7Jd"
   },
   "source": [
    "# Database Fundamentals and Applications &ndash; Group Assignment 3 &ndash; Part II. Python (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment you will use SQL code to query $\\texttt{Yelp}$ from Python. You will use the SQL results to carry out several statistical analyses. You will be asked to discuss the results&mdash;keep your answers brief; there is no need to write more than 2&ndash;4 sentences when interpreting results. Documentation of the dataset can be found in the main PDF with instructions, found on Canvas: E_EOR2_DBFA > Files > Assignments > E_EOR2_DBFA.GA3.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect Python to MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Python can connect to your MySQL Server, you need to install the MySQL-Python connector. Run the code below to install this connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gbh4HKtC3Zu",
    "outputId": "e9ddec31-c10e-44ed-9187-2561c182790c"
   },
   "outputs": [],
   "source": [
    "# install mysql connector\n",
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below to load all the necessary packages for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxftrR6GEMHU"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to establish a connection to the $\\texttt{Yelp}$ database on your local MySQL Server. **Do not forget to change the password!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "wzcFUIDcEQAd",
    "outputId": "c71bc85c-b329-41c8-ff62-a67afbaa9bca"
   },
   "outputs": [],
   "source": [
    "# connect to Yelp\n",
    "connection = mysql.connector.connect(host = \"localhost\",\n",
    "                                     user = \"root\",\n",
    "                                     password = \"your_password_goes_here\",\n",
    "                                     db = \"Yelp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you run into errors executing the code above, try restaring the kernel**: in the 'Kernel' menu, click 'Restart'. If this does not help, try installing the newest MySQL-Python connector from https://dev.mysql.com/downloads/connector/python/8.0.html. Do not forget to restart the kernel after installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas' read_sql_query() to extract data from MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part II of the assignment, we urge you to primarily use Python's Pandas package to extract, clean, and reshape data. The code below demostrates how to execute a SQL statement using Pandas, and extract a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIx5NYLeEsQa"
   },
   "outputs": [],
   "source": [
    "# select first 10k rows from Reviews\n",
    "data = pd.read_sql_query(\"SELECT * \\\n",
    "                          FROM Reviews \\\n",
    "                          LIMIT 10000\",\n",
    "                         connection)\n",
    "# let's inspect the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works as it is supposed to, you should now see a table with 8 columns: review_id, business_id, user_id, stars, cool, funny, useful and date. Now you are ready to start the actual work on Part II of Group Assignment 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xS9qJ5UPEzlZ",
    "outputId": "d1d71e02-9e18-4382-ce63-0af786fbe127"
   },
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uEGigFkC6UP"
   },
   "source": [
    "### Problem 1: Reviews (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been asked to provide an overview of the reviews left by Yelp users. In particular, we are interested to investigate:\n",
    "- the distribution of the reviews in terms of the rating,\n",
    "- the distribution of the total amount of reviews left per user, and\n",
    "- a possible relationship between the number of reviews left and the average star rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Stars distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SELECT statement that counts the number of reviews per star rating. That is, how many reviews received one star? How many two stars? Etc. In your query, order the results from the highest to the lowest count and only include reviews left before 2019.\n",
    "- Python: Execute the SQL query. Visualise the data in the resulting DataFrame using a bar plot. Using the same DataFrame, calculate the average star rating across the entire $\\texttt{Yelp}$ database. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the results with a barplot, with stars (x-axis) and counts (y-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overall average star rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Review count and star distribution among users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SELECT statement that counts the reviews and their average star rating grouped by user. Exclude users that joined less than a year before the user that was latest to join as a reviewer (so if e.g. the last user joined on March 28, 2020, exclude all users that joined on March 29, 2019 or later). Hint: use a subquery to do this (you might find this function useful https://dev.mysql.com/doc/refman/8.0/en/date-and-time-functions.html#function_date-add). Users that have never left a review should also be ignored. \n",
    "- Python: Execute the SQL query. **Warning!** Due to the size of data, this query can easily take up to 15 minutes to run. Remove users that have left more than 15 reviews. Visualise the review count distribution in a histograms. What pattern(s) do you observe?\n",
    "- Python: Group the data by count and calculate average and median of stars. Compare median and mean results, and discuss their similarity or difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rows where review counts is > 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram for number of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean of average star rating for each count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate median of average star rating for each count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Investigate relationship between number of reviews and star rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SELECT statement that returns all of the reviews written by the user as well as the count of reviews they left. Hint: use a window function. Exclude users that joined less than a year before the user that was latest to join as a reviewer. Users that have never left a review should also be ignored. \n",
    "- Python: Execute the SQL query. **Warning!** Due to the size of data, this query can easily take up to 15 minutes to run. Visualise the star distribution among users that have left only one review and the ones that have left 10 or more reviews using pie charts. What main differences do you see between the two pie charts? Briefly discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the two pie charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Business categories (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now asked to provide an overview of businesses and their categories. In particular, we are intersted to see\n",
    "- the most common business categories,\n",
    "- the distribution of average star rating per category, and\n",
    "- if there are any significant differences between categories in terms of start rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Top categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SELECT statement that returns the categories column from the Businesses table. To cut down on the amount of data, randomly sample around 5% of the data in this table. For this sampling, you may find this useful: https://phpfog.com/select-random-sample-records-mysql/. Make sure to remove rows with missing categories values.\n",
    "- Python: Execute the SQL query. The categories column has a list of categories that each business falls under. Extract every category name from each row list and store it in one big list. Display the 5 most common categories and their counts. Here, you might find these links useful: https://dev.to/courseprobe/iterate-over-rows-in-pandas-3o67; https://www.w3schools.com/python/ref_string_split.asp; https://docs.python.org/3/library/collections.html#collections.Counter.most_common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract separate categories from categories list column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give counts of the 5 most common categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Review differences between top categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SELECT statement that returns an average rating of each restaurant. Create an extra column that returns only one category based on what is contained in the categories column list. The five categories that interest us are (sorted from most to least important): (1) 'Restaurants', (2) 'Shopping', (3) 'Food', (4) 'Home Services', (5) 'Beauty & Spas'. E.g. if the list of the categories column includes the word 'Restaurants' your column should return only 'Restaurants' and ignore any other categories in the list. If, for example, the categories list contains ['Shopping', 'Food', 'Restaurants'] your column should only return 'Restaurants'. You may find the LIKE and CASE WHEN statements useful to carry out the task. Businesses that have less than 5 reviews or do not fall into any category we are interested in should be ignored.\n",
    "- Python: Execute the SQL query. **Warning!** Due to the size of data, this query can easily take up to 15 minutes to run. Visualise the distribution of average star reviews for each category in seperate plots. Describe what you observe.\n",
    "- Python: Calculate mean of the average star rating for each category. Perform a Kolmogorov-Smirnov test to see if the distributions of 'Food' and 'Restaurants' category types are significantly different. Here, you might find this useful: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the distribution of average star rating with 5 separate histograms (for each category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of average star rating for each (of the 5) business category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Kolmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Differences in restaurant star rating across states (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now been asked to investigate if there is any association between the location of the **restaurant** and its star rating. Here, you will perform linear regression using state dummies as regressors, in order to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Investigate which states have the most restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Create a (virtual) view called popular_businesses. It should include the ids of businesses that have at least 10 reviews. **Warning!** Carry out this statement in MySQL Workbench, and not via Python. Provide the statement you used below.\n",
    "- SQL: Write a SQL statement that counts how many restaurants there are in each state. Only include restaurants that appear in the popular_businesses View. Order states by the number of restaurants in descending order.\n",
    "- Python: Execute the last SQL statement. Identify which states have more than 1,500 restaurants (you will use these states in 3.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement to create the view:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which states have more than 1500 restraurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create table containing regressors (state dummies) and regressand (star ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SQL: Write a SQL statement that, for each restaurant, returns its (1) business id, (2) average star review rating, and (3) the state in which the restaurant is situated. Make sure this query only returns data on restaurants that are located in the states with more than 1,500 restaurants that you have identified in 3.1. Moreover, make sure to only include restaurants that have at least 10 reviews.\n",
    "- Python: Execute the SQL query. Transform the state column into a set of dummy variables, $d_k$ for $k=1,\\ldots,K$, where the $k$-th dummy variable equals 1 for observation $i$ if restaurant $i$ is in the state $k$, and 0 for observation $i$ if restaurant $i$ is not located in state $k$. Gather all data in a DataFrame named dummy_data. In this DataFrame make sure the 1st column is the business id, the 2nd column the average star rating of the restaurant, and the remaining columns are the state dummies. Here, you might find this useful: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy columns\n",
    "dummy_data ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Perform linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python: fill in the code below (...) to correctly perform linear regression on the dummy data frame that you have prepared in 3.2. Compute the $p$-value and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regressors and outcome\n",
    "vY = np.array(dummy_data.iloc[:,1])\n",
    "mX = np.array(dummy_data.iloc[:,2:]).astype('float64')\n",
    "# get sample size\n",
    "iN = ...\n",
    "# reshape outcome as column vector\n",
    "vY = np.reshape(vY,(iN,1))\n",
    "# under H1: regressors are intercept + all dummies except the last\n",
    "mX = np.hstack((np.ones((iN,1)),mX[:,0:-1]))\n",
    "# get number of regressors under H1\n",
    "iK1 = ...\n",
    "# under H0: just an intercept\n",
    "iK0 = 1\n",
    "# compute inv(X'X) and X'y\n",
    "mInvXTX = np.linalg.inv(...)\n",
    "vXTY = ...\n",
    "# compute OLS estimates as inv(X'X)X'y under H1\n",
    "vBetaHat = mInvXTX@vXTY\n",
    "# compute residuals under H1\n",
    "vResid1 = ...\n",
    "# compute the residuals under H0 by subtracing the mean from the outcome\n",
    "vResid0 = vY - np.mean(vY)\n",
    "# compute squared sum of residuals under H0 and H1\n",
    "dSSR1 = ...\n",
    "dSSR0 = ...\n",
    "# compute degrees of freedom F-test stat\n",
    "iDFnum = iK1 - iK0\n",
    "iDFden = iN - iK1\n",
    "# compute F-test stat\n",
    "dF = ((dSSR0 - dSSR1)/iDFnum)/(dSSR1/iDFden)\n",
    "# use the stats.f.cdf function to compute the P-value\n",
    "dPval = 1 - stats.f.cdf(..., ..., ...)\n",
    "# print P-value\n",
    "print('P-value = ' + str(dPval) + ' for F-test statistic = ' + str(dF) + ' with ' + str(iDFnum) + ' numerator d.o.f. and ' + str(iDFden) + ' denominator d.o.f.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your discussion here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us to the end of Group Assignment 3. Do not forget to save your Jupyter Notebook!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Yelp-assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
